p8105_hw2_sc5078
================
Yvonne Chen
2023-10-03

# Problem 1

Load the tidyverse library

Import three datasets

``` r
## finds my current working directory
getwd()
```

    ## [1] "/Users/YvonneChen/Desktop/p8105_hw2_sc5078"

``` r
## Import and clean pols_month.cvs datasets
pols_month = read.csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names()|>
  separate(mon, into=c("year", "month", "day"), convert = TRUE) |>
  mutate(
    month = month.name[month],
    president = 
      case_match(
        prez_gop, 
        0 ~ "democratic",
        1 ~ "republican", 
        2 ~ "republican"),
    president = as.factor(president)) |>
  select(-day, -prez_dem,-prez_gop)
```

``` r
## Import and clean snp.csv datasets
snp = read.csv("./data/fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names()|>
  separate(date, into=c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(
    year = year + 2000,
    month = month.name[month]) |>
  select(year, month, close)
```

``` r
## Import and clean unemployment.csv datasets
unemployment = read.csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec,
    names_to = "month", 
    values_to = "unemployment")
```

Join the datasets by merging snp into pols, and merging unemployment
into the result

``` r
## merging snp into pols then merging unemployment into them
prob1 = 
  left_join(pols_month, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(prob1)
```

    ## 'data.frame':    822 obs. of  11 variables:
    ##  $ year        : num  1947 1947 1947 1947 1947 ...
    ##  $ month       : chr  "January" "February" "March" "April" ...
    ##  $ gov_gop     : int  23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : int  51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : int  253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : int  23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : int  45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : int  198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : Factor w/ 2 levels "democratic","republican": 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ close       : num  NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num  NA NA NA NA NA NA NA NA NA NA ...

The pols_month dataset has 822 observations of 9 variables related to
the number of national politicians who are democratic or republican at
any given time. The snp dataset has 787 observations of 3 variables
related to Standard & Poor’s stock market index (S&P), often used as a
representative measure of stock market as a whole at given time. The
unemployment dataset has 816 observations of 3 variables describe the
unemployment rate at given time. After merging these datasets, we got
all the information happened at the same month and year. There are “NA”
values in the `close` and `unemployment` variables, which indicate that
the value of these variables is missing at those times.

# Problem 2

Read and clean the Mr. Trash Wheel sheet, update the data to include a
new homes_powered variable based on Homes powered note

``` r
Mr_trash = read_excel(
  "./data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",
  range = "A2:N586",
  col_names = TRUE,
  na = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = ) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = weight_tons * 500 / 30,
    year = as.numeric(year)
  )
```

Clean Professor Trash Wheel and Gwynnda datasets

``` r
## import and clean Professor Trash Wheel
Prof_trash = read_excel(
  "./data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  range = "A2:M108",
  col_names = TRUE,
  na = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = ) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = weight_tons * 500 / 30,
    year = as.numeric(year)
  )

## import and clean Gwynnda Trash Wheel
Gwynnda = read_excel(
  "./data/202309 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = "A2:L157",
  col_names = TRUE,
  na = "",
  trim_ws = TRUE,
  skip = 0,
  n_max = ) |>
  janitor::clean_names() |>
  mutate(
    homes_powered = weight_tons * 500 / 30,
    year = as.numeric(year)
  )
```

Combine these with the Mr. Trash Wheel dataset to produce a single tidy
dataset.

``` r
## add an additional variable to all datasets
Prof_trash <- mutate(Prof_trash, trash_wheel = "Professor Trash Wheel")
Gwynnda <- mutate(Gwynnda, trash_wheel = "Gwynnda Trash Wheel")
Mr_trash <- mutate(Mr_trash, trash_wheel = "Mr. Trash Wheel")

## Convert year variable in Prof_trash from double to numerical

## Combine three datasets
prob2 = bind_rows(Mr_trash, Prof_trash, Gwynnda)

str(prob2)
```

    ## tibble [845 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:845] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:845] "May" "May" "May" "May" ...
    ##  $ year              : num [1:845] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:845], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:845] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:845] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:845] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:845] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:845] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:845] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ plastic_bags      : num [1:845] 584 496 1080 896 368 ...
    ##  $ wrappers          : num [1:845] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : num [1:845] 7.2 5.2 6 6 7.2 5.2 3.2 6.4 5.6 7.2 ...
    ##  $ homes_powered     : num [1:845] 71.8 45.7 57.5 51.7 67.7 ...
    ##  $ trash_wheel       : chr [1:845] "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" ...

Notice that there are some `NA` values in the `sports_balls`,
`wrappers`, and `glass_bottles` variables, which indicate that the value
of these variables is missing at those locations.

Let’s talk about the prob2 datasets. The `Mr_trash` data has 584
observations and 15 variables and tells us about the weight of trash and
specific amount in different types of trash in each dumpster for a given
year from years 2014 to 2023. It also tells us how many homes in
Maryland can be powered with incinerating trash, the average homes can
be powered by Mr. Trash Wheel was 54. The `Prof_trash` data has 106
observations and 14 variables, ranging from years 2017 to 2023. The
average homes can be powered by Professor Trash Wheel was 34. The
`Gwynnda` data has 155 observations and 13 variables ranging from years
2021 to 2023. The average homes can be powered by Gwynnda Trash Wheel
was 49. The average homes powered by three trash wheels was 50. The
total weight of trash collected by Professor Trash Wheel was 216.26
tons. The total number of cigarette butts collected by Gwynnda in July
of 2021 was 1.63^{4}.

# Problem 3

Import, clean, and tidy the dataset of baseline demographics so that sex
and APOE4 carrier status are appropriate encoded (i.e. not numeric), and
remove any participants who do not meet the stated inclusion criteria
(i.e. no MCI at baseline).

``` r
## import and clean the baseline dataset
baseline = read.csv("./data/data_mci/MCI_baseline.csv", skip = 1, na.strings = ".") |>
  janitor::clean_names()|>
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"), 
    sex = as.factor(sex),
    apoe4 = 
      case_match(
        apoe4, 
        1 ~ "APOE4 carrier", 
        0 ~ "APOE4 non-carrier"),
    apoe4 = as.factor(apoe4)) |>
  drop_na(age_at_onset)

str(baseline)
```

    ## 'data.frame':    97 obs. of  6 variables:
    ##  $ id          : int  3 5 7 13 14 18 22 26 30 39 ...
    ##  $ current_age : num  62.5 66 66.5 63.1 58.4 67.8 67.3 64.8 66.3 68.3 ...
    ##  $ sex         : Factor w/ 2 levels "female","male": 2 2 2 2 1 2 1 1 1 1 ...
    ##  $ education   : int  16 16 18 12 20 16 20 20 12 16 ...
    ##  $ apoe4       : Factor w/ 2 levels "APOE4 carrier",..: 1 2 2 1 2 2 1 1 2 1 ...
    ##  $ age_at_onset: num  66.8 68.7 74 69 66.2 69.8 74.6 71.1 73.1 70.2 ...

Important steps in the import process: First, we need to import the
baseline dataset by using `read.csv()`. The first row is the label of
each variables, so use `skip = 1` to skip the first row. We also need to
set “.” in the dataset as missing value with `na.strings = "."`. Then we
use `janitor::clean_names()` to clean and standardize the column names.
Sex and APOE4 carrier status should be categorical variables, so set sex
= 1 as male, sex = 0 as female, apoe4 = 1 as APOE4 carrier, and apoe4 =
0 as APOE4 non-carrier with `case_match()`. Use `as.factor()` to change
`sex` and `apoe4` from a numeric to a factor variable. Finally, use
`drop_na()` to remove any participants with no MCI at baseline.

Relevant features of the dataset: The `baseline` data has 97
observations and 6 variables and tells us about basic demographic
information were measured at the study baseline, age of MCI onset, and
whether the participate is a APOE4 carrier. In the baseline dataset, 484
participants were recruited, and of these 97 develop MCI. The average
baseline age is 70.2628866. 0.6521739 of women in the study are APOE4
carriers.

Import, clean, and tidy the dataset of longitudinally observed biomarker
values.

``` r
rm(amyloid)
## import and clean the baseline dataset
amyloid = read.csv("./data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names()|>
  pivot_longer(
    baseline:time_8,
    names_to = "time", 
    names_prefix = "time_",
    values_to = "amyloid") |>
  mutate(
    time =
      case_match(
        time, 
        "baseline" ~ 0, 
        "2" ~ 2,
        "4" ~ 4,
        "6" ~ 6,
        "8" ~ 8),
    time = as.factor(time),
    amyloid = as.numeric(amyloid),
  ) |>
  rename(id = study_id)

str(amyloid)
```

    ## tibble [2,435 × 3] (S3: tbl_df/tbl/data.frame)
    ##  $ id     : int [1:2435] 1 1 1 1 1 2 2 2 2 2 ...
    ##  $ time   : Factor w/ 5 levels "0","2","4","6",..: 1 2 3 4 5 1 2 3 4 5 ...
    ##  $ amyloid: num [1:2435] 0.111 NA 0.109 0.105 0.107 ...

Comment on the steps on the import process: First, we need to import the
baseline dataset by using `read.csv()`. The first row is the label of
each variables, so use `skip = 1` to skip the first row. We also need to
set “.” in the dataset as missing value with `na.strings = "NA"`. Then
we use `janitor::clean_names()` to clean and standardize the column
names. The amyloid β 42/40 ratiois spread across five columns, which
correspond to five observation times. We can fix this problem using
`pivot_longer`. The original column names were informative but we
probably don’t need to keep the `time_` prefix in each case. Then we
match the character variables of each observations times to numeric
values with `case_match()`. Use `as.factor()` to change `time` from a
numeric to a factor variable. Use `as.numeric()` to change `amyloid`
from a character to numeric variable. Finally, we want to rename
“study_id” as `id`, which is the same as `id` in the `baseline` dataset.

Comment on the features of the dataset: The `amyloid` data has 2435
observations and 3 variables and tells us about the amyloid β 42/40
ratio in different time (in years) elapsed since the study baseline. The
average amyloid ratio at baseline is 0.1109638. The average amyloid
ratio at year 2 is 0.1102838. The average amyloid ratio at year 4 is
0.1099878. The average amyloid ratio at year 6 is 0.1089017. The average
amyloid ratio at year 8 is 0.1082381. There is a decreasing trend of
amyloid ratio through time.

Check whether some participants appear in only the baseline or amyloid
datasets

``` r
## Participants id that is unique in baseline dataset
participants_only_in_baseline <- anti_join(baseline, amyloid, by = "id")
unique (participants_only_in_baseline$id)
```

    ## [1]  14  49 268

``` r
## Participants id that is unique in amyloid dataset
participants_only_in_amyloid <- anti_join(amyloid, baseline)
```

    ## Joining with `by = join_by(id)`

``` r
unique (participants_only_in_amyloid$id)
```

    ##   [1]   1   2   4   6   8   9  10  11  12  15  16  17  19  20  21  23  24  25
    ##  [19]  27  28  29  31  32  33  34  35  36  37  38  40  41  42  44  46  47  48
    ##  [37]  50  51  52  53  54  56  57  58  60  61  62  63  64  66  68  70  71  73
    ##  [55]  74  79  80  81  82  83  84  85  88  90  91  93  94  95  96  97  98  99
    ##  [73] 100 101 102 103 104 105 107 108 110 111 112 113 114 115 116 117 118 119
    ##  [91] 121 122 124 125 126 127 128 129 130 131 133 134 135 136 137 138 139 140
    ## [109] 141 142 143 144 145 147 148 150 151 152 153 154 155 156 157 158 159 160
    ## [127] 161 162 163 164 165 167 168 169 171 172 173 174 175 176 178 180 181 182
    ## [145] 183 184 185 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201
    ## [163] 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 219 220 221
    ## [181] 222 223 224 225 227 228 231 232 233 235 236 237 238 239 240 241 243 244
    ## [199] 245 246 247 248 251 253 254 255 256 257 258 259 260 261 262 263 264 265
    ## [217] 266 267 269 270 271 272 273 274 275 276 278 279 281 282 284 285 288 290
    ## [235] 291 293 294 295 296 298 299 300 302 303 307 308 309 310 311 312 313 315
    ## [253] 316 317 318 319 320 321 322 324 325 326 327 329 330 331 332 333 334 335
    ## [271] 339 340 341 342 343 344 345 346 353 354 356 357 358 359 360 361 362 363
    ## [289] 364 367 368 370 371 372 374 375 376 378 381 382 383 384 385 386 387 388
    ## [307] 390 391 392 393 394 395 396 397 399 401 402 403 404 405 406 407 410 411
    ## [325] 413 414 415 418 420 421 422 425 427 428 429 430 432 433 434 435 436 437
    ## [343] 438 439 441 443 444 445 446 447 450 451 454 455 456 457 458 459 460 461
    ## [361] 462 463 464 465 466 467 468 469 470 472 473 474 475 476 477 478 479 480
    ## [379] 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495

Findings: There are 3participants appear in only the baseline dataset.
Their ids are `unique (participants_only_in_baseline$id)`, which means
that there isn’t follow-up data about their amyloid ratio. There are 393
participants appear in only the amyloid dataset. Their ids are
`unique (participants_only_in_amyloid$id)`, which means that they do not
have basic demographic information that were measured at the study
baseline or they do not meet the stated inclusion criteria (i.e. no MCI
at baseline).

Combine the demographic and biomarker datasets so that only participants
who appear in both datasets are retained.

``` r
prob3 <- inner_join(baseline, amyloid)
```

    ## Joining with `by = join_by(id)`

``` r
str(prob3)
```

    ## 'data.frame':    470 obs. of  8 variables:
    ##  $ id          : int  3 3 3 3 3 5 5 5 5 5 ...
    ##  $ current_age : num  62.5 62.5 62.5 62.5 62.5 66 66 66 66 66 ...
    ##  $ sex         : Factor w/ 2 levels "female","male": 2 2 2 2 2 2 2 2 2 2 ...
    ##  $ education   : int  16 16 16 16 16 16 16 16 16 16 ...
    ##  $ apoe4       : Factor w/ 2 levels "APOE4 carrier",..: 1 1 1 1 1 2 2 2 2 2 ...
    ##  $ age_at_onset: num  66.8 66.8 66.8 66.8 66.8 68.7 68.7 68.7 68.7 68.7 ...
    ##  $ time        : Factor w/ 5 levels "0","2","4","6",..: 1 2 3 4 5 1 2 3 4 5 ...
    ##  $ amyloid     : num  0.106 0.109 0.106 NA 0.106 ...

Describe the resulting dataset: The `prob3` datasets combine the
demographic and biomarker datasets including only participants who
appear in both datasets. There are 94 participants in the dataset of 8
variables. The dataset tells us about basic demographic information were
measured at the study baseline, age of MCI onset, whether the
participate is a APOE4 carrier, and the amyloid β 42/40 ratio in
different time (in years) elapsed since the study baseline.

Export the result as a CSV to your data directory:

``` r
write.csv(prob3, file = "./data/prob3.csv", row.names = FALSE)
```
